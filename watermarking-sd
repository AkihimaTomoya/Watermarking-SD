#!/usr/bin/env python3
"""
Script to integrate watermark decoder into a Stable Diffusion checkpoint
Converts the guided-diffusion watermark implementation to work with Stable Diffusion
"""

import torch
import torch.nn as nn
from pathlib import Path
import json
import argparse
from typing import Optional, Dict, Any
import numpy as np
from safetensors import safe_open
from safetensors.torch import save_file


class StegaStampDecoder(nn.Module):
    """
    Watermark decoder compatible with Stable Diffusion
    Modified from the original to work with different resolutions
    """
    def __init__(self, resolution=512, image_channels=3, fingerprint_size=48):
        super(StegaStampDecoder, self).__init__()
        self.resolution = resolution
        self.image_channels = image_channels
        self.fingerprint_size = fingerprint_size
        
        # Calculate the final feature size based on resolution
        # After 5 conv layers with stride 2, resolution reduces by 32x
        final_size = resolution // 32
        final_features = final_size * final_size * 128
        
        self.decoder = nn.Sequential(
            nn.Conv2d(image_channels, 32, (3, 3), 2, 1),  # /2
            nn.ReLU(),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, 2, 1),  # /4
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, 2, 1),  # /8
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, 2, 1),  # /16
            nn.ReLU(),
            nn.Conv2d(128, 128, (3, 3), 2, 1),  # /32
            nn.ReLU(),
        )
        
        self.dense = nn.Sequential(
            nn.Linear(final_features, 512),
            nn.ReLU(),
            nn.Linear(512, fingerprint_size),
        )

    def forward(self, image):
        # Ensure input has the right dtype
        target_dtype = next(self.decoder.parameters()).dtype
        if image.dtype != target_dtype:
            image = image.to(dtype=target_dtype)
        
        x = self.decoder(image)
        x = x.view(x.size(0), -1)  # Flatten
        return self.dense(x)

    def convert_to_fp16(self):
        """Convert model to fp16"""
        return self.half()
    
    def convert_to_fp32(self):
        """Convert model back to fp32"""
        return self.float()


class WatermarkIntegratedUNet(nn.Module):
    """
    Wrapper that integrates watermark functionality into Stable Diffusion UNet
    """
    def __init__(self, original_unet, watermark_decoder: StegaStampDecoder, 
                 wm_strength: float = 0.1):
        super().__init__()
        self.unet = original_unet
        self.watermark_decoder = watermark_decoder
        self.wm_strength = wm_strength
        
        # Add watermark embedding layer
        # This projects the watermark to the same dimension as time embedding
        if hasattr(original_unet, 'time_embed'):
            time_embed_dim = original_unet.time_embed[0].in_features * 4
        else:
            time_embed_dim = 1280  # Default for SD 1.5
            
        self.wm_embed = nn.Sequential(
            nn.Linear(watermark_decoder.fingerprint_size, time_embed_dim),
            nn.SiLU(),
            nn.Linear(time_embed_dim, time_embed_dim),
        )

    def forward(self, sample, timestep, encoder_hidden_states, watermark=None, **kwargs):
        """
        Forward pass with optional watermark integration
        """
        # If watermark is provided, integrate it into the process
        if watermark is not None:
            # Embed watermark
            wm_emb = self.wm_embed(watermark)
            
            # Add watermark embedding to time embedding
            # This requires modification of the UNet's time embedding
            if hasattr(self.unet, 'time_embed'):
                # Store original forward method if not already stored
                if not hasattr(self, '_original_forward'):
                    self._original_forward = self.unet.forward
                
                # Temporarily modify time embedding
                original_time_embed = self.unet.time_embed
                
                def modified_time_embed(timesteps):
                    t_emb = original_time_embed(timesteps)
                    return t_emb + self.wm_strength * wm_emb
                
                self.unet.time_embed = modified_time_embed
                
                try:
                    result = self.unet(sample, timestep, encoder_hidden_states, **kwargs)
                finally:
                    # Restore original time embedding
                    self.unet.time_embed = original_time_embed
                
                return result
        
        # Standard forward pass without watermark
        return self.unet(sample, timestep, encoder_hidden_states, **kwargs)

    def extract_watermark(self, generated_image):
        """
        Extract watermark from generated image
        """
        return self.watermark_decoder(generated_image)


def load_stable_diffusion_checkpoint(checkpoint_path: str) -> Dict[str, Any]:
    """
    Load Stable Diffusion checkpoint from either .ckpt or .safetensors format
    """
    checkpoint_path = Path(checkpoint_path)
    
    if checkpoint_path.suffix == '.safetensors':
        state_dict = {}
        with safe_open(checkpoint_path, framework="pt", device="cpu") as f:
            for key in f.keys():
                state_dict[key] = f.get_tensor(key)
        return {"state_dict": state_dict}
    
    elif checkpoint_path.suffix in ['.ckpt', '.pt', '.pth']:
        return torch.load(checkpoint_path, map_location='cpu')
    
    else:
        raise ValueError(f"Unsupported checkpoint format: {checkpoint_path.suffix}")


def integrate_watermark_into_checkpoint(
    checkpoint_path: str,
    output_path: str,
    watermark_decoder_path: Optional[str] = None,
    fingerprint_size: int = 48,
    resolution: int = 512,
    image_channels: int = 3
):
    """
    Integrate watermark decoder into Stable Diffusion checkpoint
    """
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = load_stable_diffusion_checkpoint(checkpoint_path)
    
    # Create watermark decoder
    watermark_decoder = StegaStampDecoder(
        resolution=resolution,
        image_channels=image_channels,
        fingerprint_size=fingerprint_size
    )
    
    # Load pre-trained watermark decoder if provided
    if watermark_decoder_path and Path(watermark_decoder_path).exists():
        print(f"Loading pre-trained watermark decoder from {watermark_decoder_path}")
        wm_state_dict = torch.load(watermark_decoder_path, map_location='cpu')
        watermark_decoder.load_state_dict(wm_state_dict)
    else:
        print("Using randomly initialized watermark decoder")
    
    # Add watermark components to checkpoint
    state_dict = checkpoint.get('state_dict', checkpoint)
    
    # Add watermark decoder parameters
    for name, param in watermark_decoder.named_parameters():
        key = f"watermark_decoder.{name}"
        state_dict[key] = param
    
    # Create watermark embedding layer
    # Find UNet time embedding dimension from checkpoint
    time_embed_keys = [k for k in state_dict.keys() if 'time_embed' in k and 'weight' in k]
    if time_embed_keys:
        # Get time embedding dimension
        first_time_embed = state_dict[time_embed_keys[0]]
        time_embed_dim = first_time_embed.shape[0]
    else:
        time_embed_dim = 1280  # Default for SD 1.5
    
    # Create watermark embedding layers
    wm_embed = nn.Sequential(
        nn.Linear(fingerprint_size, time_embed_dim),
        nn.SiLU(),
        nn.Linear(time_embed_dim, time_embed_dim),
    )
    
    for name, param in wm_embed.named_parameters():
        key = f"watermark_embed.{name}"
        state_dict[key] = param
    
    # Update checkpoint metadata
    if 'metadata' not in checkpoint:
        checkpoint['metadata'] = {}
    
    checkpoint['metadata'].update({
        'watermark_enabled': True,
        'watermark_fingerprint_size': fingerprint_size,
        'watermark_resolution': resolution,
        'watermark_channels': image_channels,
        'integration_version': '1.0'
    })
    
    # Save the modified checkpoint
    output_path = Path(output_path)
    print(f"Saving watermarked checkpoint to {output_path}...")
    
    if output_path.suffix == '.safetensors':
        # Save as safetensors
        save_file(state_dict, output_path)
        
        # Save metadata separately
        metadata_path = output_path.with_suffix('.json')
        with open(metadata_path, 'w') as f:
            json.dump(checkpoint.get('metadata', {}), f, indent=2)
    else:
        # Save as .ckpt
        torch.save(checkpoint, output_path)
    
    print("Integration completed successfully!")
    
    return checkpoint


def create_watermark_pipeline_config(output_dir: str):
    """
    Create configuration files for using the watermarked model
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    config = {
        "watermark_config": {
            "fingerprint_size": 48,
            "strength": 0.1,
            "extraction_threshold": 0.5
        },
        "usage_instructions": {
            "initialization": "Load the checkpoint and initialize WatermarkIntegratedUNet",
            "text2img": "Use watermark parameter in forward() call",
            "extraction": "Use extract_watermark() method on generated images"
        }
    }
    
    config_path = output_dir / "watermark_config.json"
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    # Create example usage script
    example_script = '''
import torch
from diffusers import StableDiffusionPipeline
import numpy as np

# Load the watermarked checkpoint
pipe = StableDiffusionPipeline.from_pretrained("path/to/watermarked/model")

# Generate a random watermark
watermark = torch.randn(1, 48)  # Batch size 1, fingerprint size 48

# Generate image with watermark
prompt = "A beautiful landscape with mountains and lakes"
image = pipe(
    prompt, 
    num_inference_steps=50,
    guidance_scale=7.5,
    watermark=watermark  # Add watermark parameter
).images[0]

# Extract watermark from generated image
extracted_wm = pipe.unet.extract_watermark(
    torch.tensor(np.array(image)).permute(2, 0, 1).unsqueeze(0).float() / 255.0
)

# Verify watermark
similarity = torch.cosine_similarity(watermark, extracted_wm).item()
print(f"Watermark similarity: {similarity:.4f}")
'''
    
    example_path = output_dir / "example_usage.py"
    with open(example_path, 'w') as f:
        f.write(example_script)
    
    print(f"Configuration files saved to {output_dir}")


def main():
    parser = argparse.ArgumentParser(description="Integrate watermark into Stable Diffusion checkpoint")
    parser.add_argument("--checkpoint", required=True, help="Path to Stable Diffusion checkpoint")
    parser.add_argument("--output", required=True, help="Output path for watermarked checkpoint")
    parser.add_argument("--watermark_decoder", help="Path to pre-trained watermark decoder")
    parser.add_argument("--fingerprint_size", type=int, default=48, help="Watermark fingerprint size")
    parser.add_argument("--resolution", type=int, default=512, help="Image resolution")
    parser.add_argument("--channels", type=int, default=3, help="Image channels")
    parser.add_argument("--config_dir", help="Directory to save configuration files")
    
    args = parser.parse_args()
    
    # Integrate watermark into checkpoint
    integrate_watermark_into_checkpoint(
        checkpoint_path=args.checkpoint,
        output_path=args.output,
        watermark_decoder_path=args.watermark_decoder,
        fingerprint_size=args.fingerprint_size,
        resolution=args.resolution,
        image_channels=args.channels
    )
    
    # Create configuration files if requested
    if args.config_dir:
        create_watermark_pipeline_config(args.config_dir)


if __name__ == "__main__":
    main()
